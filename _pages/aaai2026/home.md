---
layout: home
title: AIGOV-26
home_title: The 3rd International AI Governance Workshop (AIGOV)
subtitle: Held in conjunction with AAAI 2026 
nav_title: AIGOV-26
permalink: /
description: A workshop which aims to delve into the critical aspects of AI governance with a specific focus on the impacts of agentic and generative AI systems (e.g. LLMs) in shaping ethical and responsible practices.
nav_order: 1
---
<!-- <h5 style="text-align:center;"><a href="https://forms.gle/yP7sNyrrdd2BbfmP6">[Call for Reviewers]</a></h5>
<h5 style="text-align:center;"><a href="https://aigovernance.github.io/cfp/">[Call for Papers]</a></h5>
<h5 style="text-align:center;"><a href="https://aigovernance.github.io/ijcai2024/">[Last Event: AIGOV @ IJCAI 2024]</a></h5> -->

# Introduction

We are excited to announce the 3rd International Workshop on "**AI Governance Workshop: Alignment, Morality, Law, and Design**" (AIGOV) at the AAAI 2026, a critical event addressing the critical intersection of artificial intelligence (AI) governance, ethical alignment, and responsible deployment across autonomous systems. As AI technologies rapidly advance from generative models to sophisticated agentic systems capable of autonomous decision-making, new governance challenges emerge that existing frameworks cannot adequately address. This workshop brings together researchers, industry practitioners, and policy experts to develop actionable frameworks for safe, aligned, and accountable AI systems. Our unique focus combines technical governance mechanisms with policy integration, emphasizing "Governance by Design" approaches that embed responsibility directly into AI architectures rather than applying governance as external oversight.

**Format**: This workshop will be a hybrid event held in conjunction with [**AAAI 2026**](https://aaai.org/conference/aaai/aaai-26/), taking place on **January 26th, 2026** in Singapore. This full-day workshop combines keynote presentations, technical sessions, industry panels, and interactive discussions to provide a comprehensive overview of the topic. The format includes: opening keynote on governance principles, technical sessions on AI alignment and safety, industry panels sharing deployment experiences, lightning talks on technical solutions, poster sessions during breaks, interactive framework development, and collaborative roadmap development discussions. The workshop emphasizes practical outcomes through hands-on sessions and multi-stakeholder discussions that bridge the research, industry, and policy communities.

**Attendance**: Open to researchers, industry practitioners, policy experts, and students working on AI governance, safety, and responsible AI. Expected attendance: 120-150 participants (or as per AAAI guidance). We are looking forward to submissions on themes mentioned above, including novel governance challenges or practical implementation experiences.

# Call for Papers

We invite submissions addressing AI governance challenges, including:

- **Technical AI Governance**: Alignment methods, safety mechanisms, verification frameworks for autonomous systems.
- **Policy and Regulatory Frameworks**: Legal compliance, regulatory approaches for AI deployment, and international governance standards.
- **Ethical AI Implementation**: Bias mitigation, fairness, transparency, and accountability in AI decision-making.
- **Agentic AI Governance**: Governance frameworks specifically for autonomous decision-making systems.
- **Human-AI Collaboration**: Oversight models, collaborative approaches between humans and AI systems.
- **Industry Applications**: Case studies, deployment experiences, practical governance implementation.
- **Explainable AI**: Decision transparency, interpretability methods for governance compliance.
- **Multi-agent Coordination**: Governance mechanisms for multi-agent systems and distributed AI architectures.
- **Safety, Alignment, and Security Challenges**: Case studies, experiments, tools to address Governance, Evaluations, Monitoring, and Observability Challenges. 

**Submission Requirements**: Submissions should be in the form of a 5-page paper (+2-page references/appendix) for proceeding articles or a 2-page abstract for posters/demonstrations. All submissions should follow AAAI formatting guidelines. Accepted papers will be presented at the workshop and included in the workshop proceedings, unless the authors opt out. The review will be double-blind, so please keep your submission(s) anonymous. The accepted papers have the option to be non-archival (i.e., only hosted on the website). The non-archival papers can be relevant work presented or published in another venue or journal. 

All accepted papers and extended abstracts will be presented as posters. The program committee will select a few papers for oral presentation. There will be a poster session during the scheduled coffee breaks to facilitate and spark discussions amongst attendees. We look forward to your submissions and to seeing you at the workshop. If you have any questions, please feel free to contact the organizing committee. 

**Submission Site Information**: Please submit your work via **[**OpenReview**](https://openreview.net/group?id=AAAI.org/2026/Workshop/AIGOV)**.

# Key Dates

* Submission deadline: **October 22, 2025 (12:00 AM UTC)**
* Acceptance notification: **November 5th, 2025**
* Camera ready for accepted submissions: **December 15th, 2025**
* Workshop program: **January 26, 2025**



# Workshop Schedule

| **Time (local time)**{: .h5} | **Event**{: .h5}                  | **Speaker**{: .h5}                                                                         |
| :--------------------------- | :-------------------------------- | :----------------------------------------------------------------------------------------- |
| 9:00–9:10                    | Opening                           | Himanshu Joshi                                                                             |
| 9:10–9:25                    | Spotlight Talk 1                  | Dhari Gandhi (Vector Institute for AI)                                                     |
| 9:25–9:40                    | Spotlight Talk 2                  | Dimitri (Palisade Research)                                                                |
| 9:40–10:00                   | Spotlight Talk 3                  | Djallel Bouneffouf (IBM Research)                                                          |
| 10:00–10:40                  | **Keynote Address**               | Prof. Simon Chesterman (NUS)                                                               |
| 10:40–11:00                  | Poster Session I + Coffee Break   |                                                                                            |
| 11:00–11:45                  | Panel: *Governance in Action*     | Ati, Abhijeet, Prof. Simon Chesterman, Valarie (Moderator: Himanshu Joshi)                 |
| 11:45–12:00                  | Oral Paper 5                      | *Red-Teaming Financial AI Agents: Stress-Testing Governance Protections*                   |
| 12:00–12:15                  | Oral Paper 6                      | *State-Wise Constrained Policy Shaping: Runtime Behavior Steering for Safe RL*             |
| 12:15–12:30                  | Oral Paper 7                      | *With Great Capabilities Come Great Responsibilities: Agentic Risk & Capability Framework* |
| 12:30–12:45                  | Oral Paper 1                      | *Human-Centered AI Alone Will Not Ensure a Path to Human Empowerment*                      |
| 12:45–13:00                  | Oral Paper 2                      | *Executable Governance for AI: Translating Policies into Rules Using LLMs*                 |
| 13:00–13:30                  | Poster Session II + Lunch Break   |                                                                                            |
| 13:30–14:00                  | Spotlight Talk 4                  | Adam Gleave (CEO, FAR.AI)                                                                  |
| 14:00–14:15                  | Oral Paper 8                      | *Emergent Persuasion: Will LLMs Persuade Without Being Prompted?*                          |
| 14:15–14:30                  | Oral Paper 9                      | *Data Attribution in Large Language Models via Bidirectional Gradient Optimization*        |
| 14:30–14:45                  | Oral Paper 10                     | *Frequency-Domain Model Fingerprinting for Image Autoregressive Models*                    |
| 14:45–15:00                  | Oral Paper 11                     | *Dynamic Alignment for Collective Agency: Toward a Scalable Self-Improving Framework*      |
| 15:00–15:20                  | Spotlight Talk 5                  | Prof. Sara Migliorini (University of Macau)                                                |
| 15:20–15:40                  | Spotlight Talk 6                  | Miro Pluckebaum (Oxford Martin AI Governance Initiative)                                   |
| 15:40–16:00                  | Poster Session III + Coffee Break |                                                                                            |
| 16:00–16:45                  | Industry Roundtable & Panel       | Dr. Smrite, Parishrut Jassal, Archana, Samir (Moderator: Himanshu Joshi)                   |
| 16:45–17:00                  | Oral Paper 3                      | *Public Security Threats from Low-Compute AI Models*                                       |
| 17:00–17:15                  | Oral Paper 4                      | *Behind the Words: A Comprehensive Study of Bias Detection Methods in LLMs*                |
| 17:15–17:20                  | Closing Address                   | Himanshu Joshi & Djallel Bouneffouf                                                        |


# Accepted Papers

<div class="publications">
{%- for y in page.years %}
  {% bibliography -f papers -q @*[year=2026]* %}
{% endfor %}
</div>

# Confirmed Keynote and Invited Speakers

<div class="row p-2 g-2">
      <div class="col-sm-3 p-1">
          {% include people.html name="Simon Chesterman" affiliation="NUS" url="https://law.nus.edu.sg/people/simon-chesterman/" img="/assets/img/people/simon_chesterman.jpg" %}
      </div>
      <div class="col-sm-3 p-1">
        {% include people.html name="Dhari Gandhi" affiliation="Vector Institute" url="https://www.linkedin.com/in/dhari-gandhi/" img="/assets/img/people/dhari_gandhi.jpg" %}
      </div>
      <div class="col-sm-3 p-1">
        {% include people.html name="Dmitrii Volkov" affiliation="Palisade Research" url="https://palisaderesearch.org/" img="/assets/img/people/dmitrii_volkov.jpg" %}
      </div>
        <div class="col-sm-3 p-1">
        {% include people.html name="Djallel Bouneffouf" affiliation="IBM Research" url="https://www.researchgate.net/profile/Djallel-Bouneffouf" img="/assets/img/people/djallel_bouneffouf.png" %}
      </div>
      <div class="col-sm-3 p-1">
        {% include people.html name="Adam Gleave" affiliation="FAR.AI" url="https://www.gleave.me/" img="/assets/img/people/adam_gleave.jpg" %}
      </div>
        <div class="col-sm-3 p-1">
        {% include people.html name="Sara Migliorini" affiliation="University of Macau" url="https://fll.um.edu.mo/sara-migliorini/" img="/assets/img/people/sara_migliorini.jpg" %}
      </div>
      <div class="col-sm-3 p-1">
        {% include people.html name="Miro Pluckebaum" affiliation="Oxford / GovAI" url="https://www.linkedin.com/in/miro-pluckebaum/?originalSubdomain=uk" img="/assets/img/people/miro_pluckebaum.jpg" %}
      </div>
  </div>
  <br>

# Organizing Committee

<div class="row p-2 g-2">
      <div class="col-sm-3 p-1">
      {% include people.html name="Baihan Lin" affiliation="Harvard" url="https://www.linlab.org/" img="/assets/img/people/baihan_lin2.jpg" %}
      </div>
      <div class="col-sm-3 p-1">
        {% include people.html name="Dhari Gandhi" affiliation="Vector Institute" url="https://www.linkedin.com/in/dhari-gandhi/" img="/assets/img/people/dhari_gandhi.jpg" %}
      </div>
      <div class="col-sm-3 p-1">
        {% include people.html name="Franziska Boenisch" affiliation="CISPA Helmholtz Center" url="https://franziska-boenisch.de/" img="/assets/img/people/franziska_boenisch.jpg" %}
      </div>
      <div class="col-sm-3 p-1">
        {% include people.html name="Djallel Bouneffouf" affiliation="IBM Research" url="https://www.researchgate.net/profile/Djallel-Bouneffouf" img="/assets/img/people/djallel_bouneffouf.png" %}
      </div>
      <div class="col-sm-3 p-1">
      {% include people.html name="Himanshu Joshi" affiliation="UT Austin" url="https://www.linkedin.com/in/himanshujoshimitsloan/" img="/assets/img/people/himanshu_joshi.jpg" %}
      </div>
      <div class="col-sm-3 p-1">
        {% include people.html name="Sara Migliorini" affiliation="University of Macau" url="https://fll.um.edu.mo/sara-migliorini/" img="/assets/img/people/sara_migliorini.jpg" %}
      </div>
      <div class="col-sm-3 p-1">
        {% include people.html name="Lauri Goldkind" affiliation="Fordham University" url="https://www.fordham.edu/graduate-school-of-social-service/faculty/full-time-faculty-profiles/lauri-goldkind/" img="assets/img/people/lauri_goldkind.png" %}
      </div>
      <div class="col-sm-3 p-1">
        {% include people.html name="Sedef Akinli Kocak" affiliation="Vector Institute" url="https://www.linkedin.com/in/sedefakocak/" img="assets/img/people/sedef_akinli_kocak.jpg" %}
      </div>
      <div class="col-sm-3 p-1">
        {% include people.html name="Shaina Raza" affiliation="Vector Institute" url="https://www.linkedin.com/in/shainaraza/" img="assets/img/people/shaina_raza.jpg" %}
      </div>
</div>
  <br>

# Program Committee

We would like to express our sincere gratitude to our technical program committee for generously volunteering their time and expertise to review submissions for our workshop. Their valuable contributions have been instrumental in ensuring the quality and rigor of the workshop's program. 

For the current iteration, we have Pascal Poupart (University of Waterloo), Shaina Raza (Vector Institute), Sedef Akinli Kocak (Vector Institute), Kush Varshney (IBM Research), Francesca Rossi (IBM Research), Eddie Liywalii (Centre for AI Research, South Africa), Lucas Hartman (Vector Institute), Guarav Sharma (IIT, Delhi), Shivani Shukla (University of San Francisco), Merve Hickok (Center for AI and Digital Policy), with additional members from Microsoft Research and Google DeepMind.

We also deeply appreciate the dedication and commitment to our workshop's success in our past iterations:

Tianhao Li, Ruixiang Qi, Tianliang Yao, Zecheng Zhang, Rahul Jain, Jiacheng Lu, Saai Krishnan Udayakumar, Rishit Dholakia, Haocheng Bi, Botao Zhang, Hejun Huang, Ahmed Olabisi Olajide, Mahak Shah, Chandrashekar Konda, Zhun Zhou, Zhengyu Fang, Gaurav Mishra, Rohan Kulkarni, Prithviraj Dasgupta, Imran Nasim, Akshata Kishore Moharir, Harsh NILESH PATHAK, Zhoujie Ding, Deepak Jayabalan, Utsha Saha, Aashish Sheshadri, Yuan Tian, YI HAN, Zonghao Ying, Ziyi Wang, Jahnavi Anilkumar Kachhia, Matin Khajavi, Haohang Li, Yuanjian Xu, Akaash Vishal Hazarika, Benedikt Schesch, Yue Li, Jiajing Chen, Bum Jun Kim, Junlin Guo, Qinfeng Zhu, Ramya Sree Boppana, KE WANG, Martin Meinke, Zijian Zhang, Ye Zhang, Amit Agarwal, Moncef GAROUANI, Songlin Jiang, Madiha Shakil Mirza, Abuh Ibrahim Sani, Sai Prasanna Teja Reddy Bogireddy, Pallavi Gudipati, Xiaoxia Lei, Sai Tarun Kaniganti, Victoria Abosede Ogunsanya, Shashikanta Sahoo, Maryam Taeb, Jue Xiao, Prudhvi Nethi, Rianat Abbas, Madhulekha Arunmozhi, Bala Siva Sai Akhil Malepati, Hengyang Zhou, Kshitij Chandna, Kai Xi, Ojas Gupta, Yidi Xu, Zong Ke, Vishal Shah, Chloe Zhu, Mukesh Yadav, GUANGYAN GAN, Yu Ma, Karanbir Singh, Feng Chen, Qi Song, Zhao Xu, Junlong Aaron Zhou, Chandrasekar Ramachandran, Venkat Nilesh Dadi, Linjun He, Ruchi Sharma, Botao Zhang, Bharath Mummadisetty, Reza Zakerian, Xihao Xie, Zerui Wang.


# Contact

For any questions, please contact us at **himanshujoshi@utexas.edu**.

<!-- # Sponsors

* Harvard Law School
* Icahn School of Medicine at Mount Sinai
* IBM Research
* Mila - Quebec AI Institute
* Fordham University -->
